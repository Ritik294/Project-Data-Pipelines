# Project-Data-Pipelines

# Project Overview
This project will introduce us to the core concepts of Apache Airflow. To complete the project, you will need to create your own custom operators to perform tasks such as staging the data, filling the data warehouse, and running checks on the data as the final step.

We have been provided with a project template that takes care of all the imports and provides four empty operators that need to be implemented into functional pieces of a data pipeline. The template also contains a set of tasks that need to be linked to achieve a coherent and sensible data flow within the pipeline.

We will be provided with a helpers class that contains all the SQL transformations. Thus, we won't need to write the ETL yourselves, but we will need to execute it with your custom operators.
